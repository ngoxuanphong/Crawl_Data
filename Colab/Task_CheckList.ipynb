{"cells":[{"cell_type":"markdown","metadata":{"id":"BJdq3ysAMh61"},"source":["#Import path and library"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1656297913487,"user":{"displayName":"Phong Ngô","userId":"05895397198222588499"},"user_tz":-420},"id":"Li40JiCXI-bo"},"outputs":[],"source":["import pandas as pd\n","import json\n","import os\n","import numpy as np"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":640,"status":"ok","timestamp":1656297916542,"user":{"displayName":"Phong Ngô","userId":"05895397198222588499"},"user_tz":-420},"id":"k4K0FuXyJLmc"},"outputs":[],"source":["path_lake = '/content/drive/MyDrive/Data Lake/'\n","dict_path = json.load(open(f'{path_lake}Ingestion/Day 0/Vietstock/Phong /path.json'))\n","#all_com = list(pd.read_excel(f'{path_lake}Ingestion/Day 0/Vietstock/Phong /List_Com_First (1_4).xlsx')['Symbol'])\n","# all_com = list(pd.read_excel(f'{path_lake}Ingestion/Day 0/Vietstock/Phong /List_Com_Phase2.xlsx')['Symbol'])\n","# all_com = list(pd.read_excel(f'{path_lake}Ingestion/Day 0/Vietstock/Phong /List_Com_Phase3.xlsx')['Symbol'])\n","all_com = list(pd.read_excel(f'{path_lake}Ingestion/Day 0/Vietstock/Phong /List_Com_Phase4.xlsx')['Symbol'])"]},{"cell_type":"markdown","metadata":{"id":"ehLvpKBmMnvp"},"source":["#checklist"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OLjZHgYBJT_P"},"outputs":[],"source":["def change_nan(df, path):\n","    for i in range(len(all_com)):\n","        symbol = all_com[i]\n","        path_in = f'{path}{symbol}.csv'\n","        if os.path.exists(path_in) == False:\n","            df.loc[i] = np.nan\n","    return df\n","def check_bs_path(all_com, df, path):\n","    for symbol in all_com:\n","        path_in = f'{path}{symbol}.csv'\n","        if os.path.exists(path_in):\n","            list_year = list(pd.read_csv(f'{path}{symbol}.csv').columns[1:])\n","        else:\n","            list_year = []\n","        df_finan = pd.DataFrame(columns = [['Symbol']+list_year])\n","        df_finan.loc[len(df_finan.index)] = [symbol]+list_year\n","        # print(df_finan)\n","        df = pd.concat([df, df_finan])\n","    df = df.notnull()*1\n","    df = df.reset_index(drop = True)\n","    df = change_nan(df, path)\n","    df['Symbol'] = all_com\n","    return df\n","def check_bs_by_date(all_com, path):\n","    if 'Quarter' in path:\n","        list_time = []\n","        for year in range(2000, 2023):\n","            for i in range(1,5):\n","                list_time.append(f'Q{i}/{year}')\n","    if 'Year' in path:\n","        list_time = [str(i) for i in range(2000, 2023)]\n","\n","    df = pd.DataFrame(columns = [['Symbol']+list_time])\n","    df = check_bs_path(all_com, df, path)\n","    df = df[['Symbol']+ list_time]\n","    # sheets_name = path.replace(ps_finan, '')\n","    # df.to_csv(f'{sheets_name}.csv', index = False)\n","    return df\n","# check_bs_by_date(all_com, dict_path['Ingestion']['Year']['IS']) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EIIOAI8ZJXcO"},"outputs":[],"source":["df_y_BS = check_bs_by_date(all_com, dict_path['Ingestion']['Year']['BS']) \n","df_y_IS = check_bs_by_date(all_com, dict_path['Ingestion']['Year']['IS']) \n","df_y_CF = check_bs_by_date(all_com, dict_path['Ingestion']['Year']['CF']) \n","df_q_BS = check_bs_by_date(all_com, dict_path['Ingestion']['Quarter']['BS'])\n","df_q_IS = check_bs_by_date(all_com, dict_path['Ingestion']['Quarter']['IS']) \n","df_q_CF = check_bs_by_date(all_com, dict_path['Ingestion']['Quarter']['CF']) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yRgSX4YIJY0K"},"outputs":[],"source":["def check_other(all_com, path):\n","    list_ = []\n","    for symbol in all_com:\n","        try:\n","            df = pd.read_csv(f'{path}{symbol}.csv')\n","            if 'Nothing' in df.columns:\n","                list_.append(np.nan)\n","            elif  len(df)==0:\n","                list_.append(0)\n","            else: list_.append(1)\n","        except: list_.append(np.nan)\n","    return list_"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"DCKbdBfIJbCu"},"outputs":[],"source":["df_other = pd.DataFrame({'Symbol' : all_com,\n","                        'DividendCash':check_other(all_com, dict_path['Other']['DividendCash']),\n","                        'DividendShares':check_other(all_com, dict_path['Other']['DividendShares']),\n","                        'TreasuryShares':check_other(all_com, dict_path['Other']['TreasuryShares']),\n","                        'VolumeAdditionalEvents':check_other(all_com, dict_path['Other']['VolumeAdditionalEvents']),\n","                        'VolumeNow':check_other(all_com, dict_path['Other']['VolumeNow']),\n","                        'DataDownExchange':check_other(all_com, dict_path['Other']['DataDownExchange'])})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GaOxMQmGJceZ"},"outputs":[],"source":["with pd.ExcelWriter('/content/drive/MyDrive/Data Lake/Ingestion/Day 0/Vietstock/Phong /Check_Phase/CheckVietstockYear_1.xlsx') as writer:\n","    df_y_IS.to_excel(writer, sheet_name = 'IncomeStatement')\n","    df_y_BS.to_excel(writer, sheet_name = 'BalanceSheet')\n","    df_y_CF.to_excel(writer, sheet_name = 'CashFlow')\n","    df_other.to_excel(writer, sheet_name = 'Other')\n","with pd.ExcelWriter('/content/drive/MyDrive/Data Lake/Ingestion/Day 0/Vietstock/Phong /Check_Phase/CheckVietstockQuarter_1.xlsx') as writer:\n","    df_q_IS.to_excel(writer, sheet_name = 'IncomeStatement')\n","    df_q_BS.to_excel(writer, sheet_name = 'BalanceSheet')\n","    df_q_CF.to_excel(writer, sheet_name = 'CashFlow')"]},{"cell_type":"markdown","metadata":{"id":"P9x_OMwhMj4n"},"source":["#Checklist vietstock"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JG7ox4gNbnZr"},"outputs":[],"source":["def check_bs_path(all_com, df, path):\n","    for symbol in all_com:\n","        list_year = list(pd.read_csv(f'{path}{symbol}.csv').columns[1:])\n","        df_finan = pd.DataFrame(columns = [['Symbol']+list_year])\n","        df_finan.loc[len(df_finan.index)] = [symbol]+list_year\n","        # print(df_finan)\n","        df = pd.concat([df, df_finan])\n","    df = df.notnull()*1\n","    df['Symbol'] = all_com\n","    return df\n","def check_bs_by_date(all_com, path, time):\n","    if time == 'QUY':\n","        list_time = []\n","        for year in range(2000, 2023):\n","            for i in range(1,5):\n","                list_time.append(f'Q{i}/{year}')\n","    if time == 'NAM':\n","        list_time = [str(i) for i in range(2000, 2023)]\n","\n","    df = pd.DataFrame(columns = [['Symbol']+list_time])\n","    df = check_bs_path(all_com, df, path)\n","    df = df[['Symbol']+ list_time]\n","    # sheets_name = path.replace(ps_finan, '')\n","    # df.to_csv(f'{sheets_name}.csv', index = False)\n","    return df\n","# check_bs_by_date(all_com, ps_y_BS, 'NAM')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5bTvq2NQoV8T"},"outputs":[],"source":["df_y_BS = check_bs_by_date(all_com, dict_path['Phong']['Year']['BS'],'NAM') \n","# df_q_BS = check_bs_by_date(all_com, dict_path['Phong']['Quarter']['BS'])\n","df_y_IS = check_bs_by_date(all_com, dict_path['Phong']['Year']['IS'],'NAM') \n","# df_q_IS = check_bs_by_date(all_com, dict_path['Vietstock_F1']['Quarter']['IS']) \n","df_y_CF = check_bs_by_date(all_com, dict_path['Phong']['Year']['CF'],'NAM')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2_P4Ywns6yY"},"outputs":[],"source":["path = p_DividendCash\n","symbol = 'AAA'\n","def check_other(all_com, path):\n","    list_ = []\n","    for symbol in all_com:\n","        df = pd.read_csv(f'{path}{symbol}.csv')\n","        if  len(df)==0:\n","            list_.append(0)\n","        else: list_.append(1)\n","    return list_\n","# check_other(all_com, path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mtfcRXrDuVc1"},"outputs":[],"source":["df_other = pd.DataFrame({'Symbol' : all_com,\n","                        'DividendCash':check_other(all_com, p_DividendCash),\n","                        'DividendShares':check_other(all_com, p_DividendShares),\n","                        'TreasuryShares':check_other(all_com, p_TreasuryShares),\n","                        'VolumeAdditionalEvents':check_other(all_com, p_VolumeAdditionalEvents),\n","                        'VolumeNow':check_other(all_com, p_VolumeNow)})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ivMZvDzHcO7"},"outputs":[],"source":["with pd.ExcelWriter('/content/drive/MyDrive/Data Lake/Ingestion/Day 0/Vietstock/Phong /Check_Phase/CheckVietstockYear_2.xlsx') as writer:\n","    df_y_IS.to_excel(writer, sheet_name = 'IncomeStatement')\n","    df_y_BS.to_excel(writer, sheet_name = 'BalanceSheet')\n","    df_y_CF.to_excel(writer, sheet_name = 'CashFlow')\n","#     df_other.to_excel(writer, sheet_name = 'Other')\n","# with pd.ExcelWriter('/content/drive/MyDrive/Data Lake/Ingestion/Day 0/Vietstock/Phong /CheckVietstockQuarter.xlsx') as writer:\n","#     df_q_IS.to_excel(writer, sheet_name = 'IncomeStatement')\n","#     df_q_BS.to_excel(writer, sheet_name = 'BalanceSheet')\n","#     df_q_CF.to_excel(writer, sheet_name = 'CashFlow')"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPR2NQY5iNJIMI3nzse3EM6","collapsed_sections":[],"mount_file_id":"1It2V4qLOUrU4TNM9yu1Rllf7zxb9xrSL","name":"Task_CheckList.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}